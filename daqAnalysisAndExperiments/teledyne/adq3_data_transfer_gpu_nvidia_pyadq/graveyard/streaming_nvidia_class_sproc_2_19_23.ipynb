{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 device(s)\n",
      "Setting up data collection for: <ADQ S/N: SPD-10702>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Error 12 from function gdr_pin_buffer.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Error 12 from function gdr_pin_buffer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dradmin/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2023 Teledyne Signal Processing Devices Sweden AB\n",
    "\"\"\" P2P streaming ADQ -> GPU in python \"\"\"\n",
    "\n",
    "import pyadq\n",
    "from typing import List, Tuple\n",
    "import cupy as cp\n",
    "import settings as s\n",
    "import ctypes as ct\n",
    "import streaming_helpers as sh\n",
    "import helper_cupy as hc\n",
    "import gdrapi as g\n",
    "from gdrapi import gdr_check_error_exit_func\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cupyx.scipy.fft as cufft\n",
    "import scipy.fft\n",
    "scipy.fft.set_global_backend(cufft)\n",
    "import threading\n",
    "import torch\n",
    "%matplotlib widget\n",
    "\n",
    "def allocate_and_pin_buffer(\n",
    "    buffer_size: int,\n",
    "    memory_handle: g.GdrMemoryHandle,\n",
    "    gdr: g.Gdr,\n",
    "    bar_ptr_data: sh.BarPtrData,\n",
    ") -> Tuple[ct.c_void_p, ct.c_uint64, cp.ndarray]:\n",
    "    \"\"\"Allocate and pin buffers.\n",
    "\n",
    "    Args:\n",
    "        `buffer_size`: Size to allocate on GPU.\n",
    "        `memory_handle`: Wrapped memory_handle struct from gdrapi.\n",
    "        `gdr`: Wrapped gdr object from gdrapi.\n",
    "        `bar_ptr_data`: Pointer to data on bar.\n",
    "\n",
    "    Returns:\n",
    "        `buffer_pointer`: Pointer to GPU buffer.\n",
    "        `buffer_address`: Physical address to buffer.\n",
    "        `buffer`: Buffer object.\n",
    "    \"\"\"\n",
    "    info = g.GdrInfo()\n",
    "\n",
    "    buffer_size = (buffer_size + g.GPU_PAGE_SIZE - 1) & g.GPU_PAGE_MASK\n",
    "    buffer = cp.zeros(buffer_size // 2, dtype=cp.short)  # Allocate memory in GPU\n",
    "    buffer_ptr = buffer.data.ptr  # Pointer of memory\n",
    "\n",
    "    # Map device memory buffer on GPU BAR1, returning an handle.\n",
    "    gdr_status = gdrapi.gdr_pin_buffer(\n",
    "        gdr, ct.c_ulong(buffer_ptr), buffer_size, 0, 0, ct.byref(memory_handle)\n",
    "    )\n",
    "    gdr_check_error_exit_func(gdr_status or (memory_handle == 0), \"gdr_pin_buffer\")\n",
    "    # Create a user-space mapping for the BAR1 info, length is bar1->buffer\n",
    "    gdr_status = gdrapi.gdr_map(gdr, memory_handle, ct.byref(bar_ptr_data), buffer_size)\n",
    "    gdr_check_error_exit_func(gdr_status or (bar_ptr_data == 0), \"gdr_map\")\n",
    "    # Bar physical address will be aligned to the page size before being mapped in user-space\n",
    "    # so the pointer returned might be affected by an offset.\n",
    "    # gdr_get_info is used to calculate offset.\n",
    "\n",
    "    gdr_status = gdrapi.gdr_get_info(gdr, memory_handle, info)\n",
    "\n",
    "    gdr_check_error_exit_func(gdr_status, \"gdr_info\")\n",
    "    offset_data = info.va - buffer_ptr\n",
    "\n",
    "    buffer_address = ct.c_uint64(info.physical)\n",
    "    gdr_status = gdrapi.gdr_validate_phybar(gdr, memory_handle)\n",
    "    gdr_check_error_exit_func(gdr_status, \"gdr_validate_phybar\")\n",
    "    buffer_pointer = ct.c_void_p(bar_ptr_data.value + offset_data)\n",
    "\n",
    "    return buffer_pointer, buffer_address, buffer\n",
    "\n",
    "\n",
    "\n",
    "gdrapi = g.GdrApi()\n",
    "\n",
    "acu: pyadq.ADQControlUnit = pyadq.ADQControlUnit()\n",
    "# Enable trace logging\n",
    "acu.ADQControlUnit_EnableErrorTrace(pyadq.LOG_LEVEL_INFO, \".\")\n",
    "\n",
    "# List the available devices\n",
    "device_list: List[pyadq.ADQInfoListEntry] = acu.ListDevices()\n",
    "\n",
    "print(f\"Found {len(device_list)} device(s)\")\n",
    "\n",
    "# Ensure that at least one device is available\n",
    "assert device_list\n",
    "\n",
    "# Set up the first available device\n",
    "device_to_open = 0\n",
    "dev: pyadq.ADQ = acu.SetupDevice(device_to_open)\n",
    "\n",
    "print(f\"Setting up data collection for: {dev}\")\n",
    "\n",
    "# Initialize the parameterss with default values\n",
    "parameters: pyadq.ADQParameters = dev.InitializeParameters(pyadq.ADQ_PARAMETER_ID_TOP)\n",
    "parameters.event_source.periodic.period = s.PERIODIC_EVENT_SOURCE_PERIOD\n",
    "parameters.event_source.periodic.frequency = s.PERIODIC_EVENT_SOURCE_FREQUENCY\n",
    "\n",
    "parameters.test_pattern.channel[0].source = s.CH0_TEST_PATTERN_SOURCE\n",
    "parameters.test_pattern.channel[1].source = s.CH1_TEST_PATTERN_SOURCE\n",
    "\n",
    "parameters.signal_processing.sample_skip.channel[0].skip_factor = s.CH0_SAMPLE_SKIP_FACTOR\n",
    "parameters.signal_processing.sample_skip.channel[1].skip_factor = s.CH1_SAMPLE_SKIP_FACTOR\n",
    "parameters.acquisition.channel[0].nof_records = (\n",
    "    s.NOF_RECORDS_PER_BUFFER * s.NOF_BUFFERS_TO_RECEIVE\n",
    ")\n",
    "parameters.acquisition.channel[0].record_length = s.CH0_RECORD_LEN\n",
    "parameters.acquisition.channel[0].trigger_source = s.CH0_TRIGGER_SOURCE\n",
    "parameters.acquisition.channel[0].trigger_edge = s.CH0_TRIGGER_EDGE\n",
    "parameters.acquisition.channel[0].horizontal_offset = s.CH0_HORIZONTAL_OFFSET\n",
    "\n",
    "if s.NOF_CHANNELS > 1:\n",
    "    parameters.acquisition.channel[1].nof_records = (\n",
    "        s.NOF_RECORDS_PER_BUFFER * s.NOF_BUFFERS_TO_RECEIVE\n",
    "    )\n",
    "    parameters.acquisition.channel[1].record_length = s.CH1_RECORD_LEN\n",
    "    parameters.acquisition.channel[1].trigger_source = s.CH1_TRIGGER_SOURCE\n",
    "    parameters.acquisition.channel[1].trigger_edge = s.CH1_TRIGGER_EDGE\n",
    "    parameters.acquisition.channel[1].horizontal_offset = s.CH1_HORIZONTAL_OFFSET\n",
    "\n",
    "parameters.transfer.common.write_lock_enabled = 1\n",
    "parameters.transfer.common.transfer_records_to_host_enabled = 0\n",
    "parameters.transfer.common.marker_mode = pyadq.ADQ_MARKER_MODE_HOST_MANUAL\n",
    "\n",
    "parameters.transfer.channel[0].record_length_infinite_enabled = 0\n",
    "parameters.transfer.channel[0].record_size = (\n",
    "    s.BYTES_PER_SAMPLES * parameters.acquisition.channel[0].record_length\n",
    ")\n",
    "parameters.transfer.channel[0].record_buffer_size = (\n",
    "    s.NOF_RECORDS_PER_BUFFER * parameters.transfer.channel[0].record_size\n",
    ")\n",
    "parameters.transfer.channel[0].metadata_enabled = 0\n",
    "parameters.transfer.channel[0].nof_buffers = s.NOF_GPU_BUFFERS\n",
    "\n",
    "if s.NOF_CHANNELS > 1:\n",
    "    parameters.transfer.channel[1].record_length_infinite_enabled = 0\n",
    "    parameters.transfer.channel[1].record_size = (\n",
    "        s.BYTES_PER_SAMPLES * parameters.acquisition.channel[1].record_length\n",
    "    )\n",
    "    parameters.transfer.channel[1].record_buffer_size = (\n",
    "        s.NOF_RECORDS_PER_BUFFER * parameters.transfer.channel[1].record_size\n",
    "    )\n",
    "    parameters.transfer.channel[1].metadata_enabled = 0\n",
    "    parameters.transfer.channel[1].nof_buffers = s.NOF_GPU_BUFFERS\n",
    "\n",
    "# Create pointers, buffers and GDR object\n",
    "memory_handles = [\n",
    "    [g.GdrMemoryHandle() for x in range(s.NOF_CHANNELS)] for y in range(s.NOF_GPU_BUFFERS)\n",
    "]\n",
    "bar_ptr_data = sh.BarPtrData(s.NOF_CHANNELS, s.NOF_GPU_BUFFERS)\n",
    "#print('bar', self.bar_ptr_data.pointers)\n",
    "gpu_buffer_ptr = sh.GpuBufferPointers(s.NOF_CHANNELS, s.NOF_GPU_BUFFERS)\n",
    "gdr = gdrapi.gdr_open()\n",
    "gpu_buffers = sh.GpuBuffers(\n",
    "    s.NOF_CHANNELS,\n",
    "    s.NOF_GPU_BUFFERS,\n",
    "    s.CH0_RECORD_LEN,\n",
    ")\n",
    "gpu_buffer_address = 0\n",
    "\n",
    "# Allocate GPU buffers\n",
    "for ch in range(s.NOF_CHANNELS):\n",
    "    for b in range(s.NOF_GPU_BUFFERS):\n",
    "        #print(f\"allocating ch {ch}, buffer num {b}\")\n",
    "        (\n",
    "            gpu_buffer_ptr.pointers[ch][b],\n",
    "            gpu_buffer_address,\n",
    "            gpu_buffers.buffers[ch][b],\n",
    "        ) = allocate_and_pin_buffer(\n",
    "            parameters.transfer.channel[ch].record_buffer_size,\n",
    "            memory_handles[ch][b],\n",
    "            gdr,\n",
    "            bar_ptr_data.pointers[ch][b],\n",
    "        )\n",
    "        parameters.transfer.channel[ch].record_buffer_bus_address[b] = gpu_buffer_address\n",
    "        parameters.transfer.channel[ch].record_buffer[b] = gpu_buffer_ptr.pointers[ch][b]\n",
    "# Configure digitizer parameterss\n",
    "dev.SetParameters(parameters)\n",
    "print('done allocating and configuring \\n')\n",
    "\n",
    "class avgFft:\n",
    "    def __init__(self,\n",
    "                parameters,\n",
    "                dev,\n",
    "                gpu_buffer_address,\n",
    "                gpu_buffer_ptr,\n",
    "                gpu_buffers,\n",
    "                gdr,\n",
    "                memory_handles,\n",
    "                bar_ptr_data\n",
    "                ):\n",
    "        self.parameters         = parameters\n",
    "        self.dev                = dev\n",
    "        self.gpu_buffer_address = gpu_buffer_address\n",
    "        self.gpu_buffer_ptr     = gpu_buffer_ptr\n",
    "        self.gpu_buffers        = gpu_buffers\n",
    "        self.gdr                = gdr\n",
    "        self.memory_handles     = memory_handles\n",
    "        self.bar_ptr_data       = bar_ptr_data\n",
    "\n",
    "        self.data_transfer_done = 0\n",
    "        self.nof_buffers_received = [0, 0]\n",
    "        self.bytes_received = 0\n",
    "        self.status = pyadq.ADQP2pStatus()._to_ct()\n",
    "       \n",
    "\n",
    "    def exit(self):\n",
    "        print('exiting')\n",
    "        for ch in range(s.NOF_CHANNELS):\n",
    "            for b in range(s.NOF_GPU_BUFFERS):\n",
    "                if 0:\n",
    "                    print(f\"********ch {ch}, buffer num {b}********\")\n",
    "                    print('buffer size:         ',self.parameters.transfer.channel[ch].record_buffer_size)\n",
    "                    print('buffer address:      ',self.gpu_buffer_address)\n",
    "                    print('buffer ptr:          ',self.gpu_buffer_ptr.pointers[ch][b])\n",
    "                    print('type buffer ptr:     ',type(self.gpu_buffer_ptr.pointers[ch][b]))\n",
    "                    print('buffer              ', len(self.gpu_buffers.buffers[ch][b]))\n",
    "                    print('type buffer         ', type(self.gpu_buffers.buffers[ch][b]))\n",
    "\n",
    "                gdrapi.gdr_unmap(\n",
    "                    self.gdr,\n",
    "                    self.memory_handles[ch][b],\n",
    "                    self.bar_ptr_data.pointers[ch][b],\n",
    "                    s.NOF_RECORDS_PER_BUFFER * s.CH0_RECORD_LEN * s.BYTES_PER_SAMPLES,\n",
    "                )\n",
    "                gdrapi.gdr_unpin_buffer(self.gdr, self.memory_handles[ch][b])\n",
    "                #print(self.bar_ptr_data.pointers[ch][b], '\\n')\n",
    "        # Free GPU memory\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        mempool.free_all_blocks()\n",
    "        print('done exiting')\n",
    "\n",
    "    def allocate_and_pin_buffer(\n",
    "        self,\n",
    "        buffer_size: int,\n",
    "        memory_handle: g.GdrMemoryHandle,\n",
    "        gdr: g.Gdr,\n",
    "        bar_ptr_data: sh.BarPtrData,\n",
    "    ) -> Tuple[ct.c_void_p, ct.c_uint64, cp.ndarray]:\n",
    "        \"\"\"Allocate and pin buffers.\n",
    "\n",
    "        Args:\n",
    "            `buffer_size`: Size to allocate on GPU.\n",
    "            `memory_handle`: Wrapped memory_handle struct from gdrapi.\n",
    "            `gdr`: Wrapped gdr object from gdrapi.\n",
    "            `bar_ptr_data`: Pointer to data on bar.\n",
    "\n",
    "        Returns:\n",
    "            `buffer_pointer`: Pointer to GPU buffer. ct void pointer\n",
    "            `buffer_address`: Physical address to buffer. ct uint64\n",
    "            `buffer`: Buffer object. cp.ndarray\n",
    "        \"\"\"\n",
    "        info = g.GdrInfo()\n",
    "\n",
    "        buffer_size = (buffer_size + g.GPU_PAGE_SIZE - 1) & g.GPU_PAGE_MASK\n",
    "        buffer = cp.zeros(buffer_size // 2, dtype=cp.short)  # Allocate memory in GPU\n",
    "        buffer_ptr = buffer.data.ptr  # Pointer of memory\n",
    "\n",
    "        # Map device memory buffer on GPU BAR1, returning an handle.\n",
    "        gdr_status = gdrapi.gdr_pin_buffer(\n",
    "            gdr, ct.c_ulong(buffer_ptr), buffer_size, 0, 0, ct.byref(memory_handle)\n",
    "        )\n",
    "        gdr_check_error_exit_func(gdr_status or (memory_handle == 0), \"gdr_pin_buffer\")\n",
    "        # Create a user-space mapping for the BAR1 info, length is bar1->buffer\n",
    "        gdr_status = gdrapi.gdr_map(gdr, memory_handle, ct.byref(bar_ptr_data), buffer_size)\n",
    "        gdr_check_error_exit_func(gdr_status or (bar_ptr_data == 0), \"gdr_map\")\n",
    "        # Bar physical address will be aligned to the page size before being mapped in user-space\n",
    "        # so the pointer returned might be affected by an offset.\n",
    "        # gdr_get_info is used to calculate offset.\n",
    "\n",
    "        gdr_status = gdrapi.gdr_get_info(gdr, memory_handle, info)\n",
    "\n",
    "        gdr_check_error_exit_func(gdr_status, \"gdr_info\")\n",
    "        offset_data = info.va - buffer_ptr\n",
    "\n",
    "        buffer_address = ct.c_uint64(info.physical)\n",
    "        gdr_status = gdrapi.gdr_validate_phybar(gdr, memory_handle)\n",
    "        gdr_check_error_exit_func(gdr_status, \"gdr_validate_phybar\")\n",
    "        buffer_pointer = ct.c_void_p(bar_ptr_data.value + offset_data)\n",
    "\n",
    "        return buffer_pointer, buffer_address, buffer\n",
    "\n",
    "    def acquireData(self, sem):\n",
    "        # Start timer for measurement\n",
    "        start_time = time.time()\n",
    "        # Start timer for regular printouts\n",
    "        start_print_time = time.time()\n",
    "        print(f\"Start acquiring data for: {self.dev}\")\n",
    "        if self.dev.ADQ_StartDataAcquisition() == pyadq.ADQ_EOK: #check for errors starting\n",
    "            print(\"Success. Begin Acquiring\")\n",
    "        else:\n",
    "            print(\"Failed\")\n",
    "\n",
    "\n",
    "        '''PYADQ STATUS:\n",
    "        pg 167. \n",
    "        ADQP2pStatus Members:\n",
    "            channel: Array of ADQP2pChannel structs. Each element represents a channel\n",
    "            flags: N/A\n",
    "        ADQP2pChannel members:\n",
    "            flags: N/A\n",
    "            nof_completed_buffers:\n",
    "                Number of valid entries in completed_buffers\n",
    "            completed_buffers:\n",
    "                indicies of buffers with data available to read. \n",
    "        '''\n",
    "\n",
    "        #main transfer loop. Happens NOF_BUFFERS_TO_RECEIVE times\n",
    "        acquireTime = []\n",
    "        master_start_time = time.time()\n",
    "        while not self.data_transfer_done:\n",
    "            #ti = time.time()\n",
    "            '''for ch in range(2):\n",
    "                for b in range(2):\n",
    "                    #print(f\"status before wait ch{ch} buf{b}\", self.status.channel[ch].completed_buffers[b])'''\n",
    "            #print()\n",
    "            #wait for buffers to fill. Code locks here until one transfer buffer fills \n",
    "            self.result = self.dev.ADQ_WaitForP2pBuffers(ct.byref(self.status), s.WAIT_TIMEOUT_MS)\n",
    "            #time.sleep(1)\n",
    "            '''print(\"time to wait for p2p buff:\", time.time() - ti)\n",
    "            acquireTime.append(time.time() - ti)'''\n",
    "\n",
    "            #handle errors\n",
    "            if self.result == pyadq.ADQ_EAGAIN:\n",
    "                print(\"Timeout\")\n",
    "            elif self.result < 0:\n",
    "                print(f\"Failed with retcode {self.result}\")\n",
    "                exit(1)\n",
    "            #We have a full buffer, \n",
    "            else:\n",
    "                '''for ch in range(2):\n",
    "                    for b in range(2):\n",
    "                        b\n",
    "                        #print(f\"status after wait ch{ch} buf{b}\", self.status.channel[ch].completed_buffers[b])'''\n",
    "                #sem.release()\n",
    "                buf = 0\n",
    "                fftCompleted = 0\n",
    "                #print('nof complete buffers', self.status.channel[0].nof_completed_buffers, '\\n')\n",
    "                \n",
    "                while (buf < self.status.channel[0].nof_completed_buffers) or (\n",
    "                    buf < self.status.channel[1].nof_completed_buffers\n",
    "                ):\n",
    "                    for ch in range(s.NOF_CHANNELS):\n",
    "                        if buf < self.status.channel[ch].nof_completed_buffers:\n",
    "                            \n",
    "                            self.buffer_index = self.status.channel[ch].completed_buffers[buf]\n",
    "                            #print(f'num complete buffers before unlock ch {ch} buffer 0 =', self.status.channel[ch].completed_buffers[0])\n",
    "                            #print(f'num complete buffers before unlock ch {ch} buffer 1 =', self.status.channel[ch].completed_buffers[1])\n",
    "    \n",
    "                            self.fft = torch.as_tensor(cp.zeros(s.CH0_RECORD_LEN//2 + 1), device='cuda')\n",
    "                            #self.fft = cp.zeros(s.CH0_RECORD_LEN//2 + 1)\n",
    "\n",
    "\n",
    "                                \n",
    "                            #time.sleep(1)\n",
    "                            readyBuffer = self.status.channel[1].completed_buffers[0]\n",
    "                            #print(\"ready buffer = \",readyBuffer)\n",
    "\n",
    "                            #print('on buffer: ', self.nof_buffers_received)\n",
    "                            #print('FFTs completed: ', fftCompleted)\n",
    "                \n",
    "                            bufferTensor    = torch.as_tensor(self.gpu_buffers.buffers[1][readyBuffer], device='cuda')\n",
    "                            self.fft        +=torch.abs(torch.fft.rfft(bufferTensor))\n",
    "                            \n",
    "                            print('fftCompleted:', fftCompleted)\n",
    "                            fftCompleted+=1\n",
    "\n",
    "                        \n",
    "                            self.dev.ADQ_UnlockP2pBuffers(ch, (1 << self.buffer_index)) # A mask of buffer indexes to unlock. p194\n",
    "\n",
    "                            self.nof_buffers_received[ch] += 1\n",
    "                            self.bytes_received += (\n",
    "                                s.NOF_RECORDS_PER_BUFFER * s.CH0_RECORD_LEN * s.BYTES_PER_SAMPLES\n",
    "                            )\n",
    "\n",
    "                        #self.doFFT(ch, b)\n",
    "                    buf += 1\n",
    "                    #print('buf', buf)\n",
    "                self.data_transfer_done = self.nof_buffers_received[1] >= s.NOF_BUFFERS_TO_RECEIVE\n",
    "                now_time = time.time() - start_time\n",
    "                print_time = time.time() - start_print_time\n",
    "\n",
    "\n",
    "                if print_time > 5:\n",
    "                    # Check for overflow, stop if overflow\n",
    "                    overflow_status = self.dev.GetStatus(pyadq.ADQ_STATUS_ID_OVERFLOW)\n",
    "                    if overflow_status.overflow:\n",
    "                        print(\"Overflow, stopping data acquisition...\")\n",
    "                        self.dev.ADQ_StopDataAcquisition()\n",
    "                        exit(\"Exited because of overflow.\")\n",
    "\n",
    "                    print(\"Nof buffers received:\", self.nof_buffers_received)\n",
    "                    print(\"Total GB received:\", self.bytes_received / 10**9)\n",
    "                    print(\"Average transfer speed:\", self.bytes_received / 10**9 / now_time)\n",
    "                    print(\"time since start \\n\", time.time() - master_start_time)\n",
    "                    start_print_time = time.time()\n",
    "        time.sleep(.1)\n",
    "        print(\"Done Acquiring Data \\n\")\n",
    "        stop_time = time.time()\n",
    "\n",
    "        gbps = self.bytes_received / (stop_time - start_time)\n",
    "        self.dev.ADQ_StopDataAcquisition()\n",
    "        print('########Stats########')\n",
    "        print(f'Total buffers received: {self.nof_buffers_received}')\n",
    "        print(f\"Total GB received: {self.bytes_received / 10**9}\")\n",
    "        print(f\"Total GB/s: {gbps / 10**9}\")\n",
    "        #print(np.std(acquireTime)/np.mean(acquireTime))\n",
    "\n",
    "        if s.PRINT_LAST_BUFFERS:\n",
    "            data_buffer = np.zeros(\n",
    "                self.parameters.transfer.channel[0].record_buffer_size // 2, dtype=np.short\n",
    "            )\n",
    "            print(self.gpu_buffers.buffers[0][0], '\\n')\n",
    "            hc.cudaMemcpy(\n",
    "                data_buffer.ctypes.data,                                #destantation\n",
    "                self.gpu_buffers.buffers[1][1].data.ptr,                #source\n",
    "                self.parameters.transfer.channel[1].record_buffer_size, #size\n",
    "                hc.cudaMemcpyDeviceToHost,                              #kind\n",
    "            )\n",
    "\n",
    "            #data_buffer.tofile(\"data.bin\")\n",
    "            #plotting\n",
    "            if 0:\n",
    "                plt.close('all')\n",
    "                if 0: #time domain\n",
    "                    plt.figure()\n",
    "                    plt.title('time domain')\n",
    "                    pts = [i for i in range(0, len(data_buffer))]\n",
    "                    plt.plot(pts, data_buffer)\n",
    "                    plt.xlabel('samples')\n",
    "                    plt.ylabel('ACD code')\n",
    "                    plt.show()\n",
    "\n",
    "                if 0: #time domain diff\n",
    "                    plt.figure()\n",
    "                    diff = np.diff(np.asarray(pts))\n",
    "                    plt.plot(diff)\n",
    "                    plt.show()\n",
    "\n",
    "                if 0: #bathtub\n",
    "                    plt.figure()\n",
    "                    plt.hist(data_buffer, bins = int(2**8))\n",
    "                    plt.show()\n",
    "\n",
    "                if 0: #fft\n",
    "                    length = len(data_buffer)\n",
    "                    fft = np.abs(np.fft.fft(data_buffer)[0:length//2])\n",
    "\n",
    "                    plt.figure()\n",
    "                    plt.title('FFT')\n",
    "                    fft = fft**2 * 2**-34*2/(50*length**2)*1000\n",
    "                    plt.plot(np.linspace(0,1.25,length//2)[1:],10*np.log10(fft[1:]))\n",
    "                    plt.xlabel('Frequency (GHz)')\n",
    "                    plt.ylabel('Power (dBm)')\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    def doFFT(self, sem):\n",
    "\n",
    "        start_gpu = cp.cuda.Event()\n",
    "        end_gpu = cp.cuda.Event()\n",
    "\n",
    "        fftCompleted = 0\n",
    "        \n",
    "        self.fft = torch.as_tensor(cp.zeros(s.CH0_RECORD_LEN//2 + 1), device='cuda')\n",
    "        #self.fft = cp.zeros(s.CH0_RECORD_LEN//2 + 1)\n",
    "\n",
    "        while not self.data_transfer_done:\n",
    "            ti = time.time()\n",
    "            sem.acquire()\n",
    "            \n",
    "            #time.sleep(1)\n",
    "            readyBuffer = self.status.channel[1].completed_buffers[0]\n",
    "            #print(\"ready buffer = \",readyBuffer)\n",
    "\n",
    "            #print('on buffer: ', self.nof_buffers_received)\n",
    "            #print('FFTs completed: ', fftCompleted)\n",
    "  \n",
    "            bufferTensor    = torch.as_tensor(self.gpu_buffers.buffers[1][readyBuffer], device='cuda')\n",
    "            self.fft        +=torch.abs(torch.fft.rfft(bufferTensor))\n",
    "            \n",
    "\n",
    "            fftCompleted+=1\n",
    "\n",
    "            #self.fft2 += cp.asarray(\n",
    "            #                np.abs(scipy.fft.rfft(self.gpu_buffers.buffers[0][readyBuffer])),\n",
    "            #                dtype=cp.float_)\n",
    "            #print(\"type outAtt\", (self.outArr[1])) #\n",
    " \n",
    "\n",
    "        print('Total FFTs completed: ', fftCompleted)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "            for ch in range(2):\n",
    "                for b in range(2):\n",
    "                    if ch == 1:\n",
    "                        ch\n",
    "                        #print(f'buffer ch {ch} buffer{b} =', self.gpu_buffers.buffers[ch][b])\n",
    "                        #print(f'num complete buffers ch {ch} buffer{b} =', self.status.channel[ch].nof_completed_buffers)\n",
    "            #print(time.time() -ti)\n",
    "            #print()'''\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    myclass = avgFft(parameters,\n",
    "                dev,\n",
    "                gpu_buffer_address,\n",
    "                gpu_buffer_ptr,\n",
    "                gpu_buffers,\n",
    "                gdr,\n",
    "                memory_handles,\n",
    "                bar_ptr_data)\n",
    "\n",
    "    sem             = threading.Semaphore(0)\n",
    "    acquireThread   = threading.Thread(target=myclass.acquireData,\n",
    "                                    args=(sem,))\n",
    "    #doFFTThread     = threading.Thread(target=myclass.doFFT,\n",
    "                                    #args=(sem,))\n",
    "\n",
    "\n",
    "''''\n",
    "    avgPowSpec = []\n",
    "    for i in range(2):\n",
    "        print('taking run', i)\n",
    "        myclass = avgFft(parameters,\n",
    "            dev,\n",
    "            gpu_buffer_address,\n",
    "            gpu_buffer_ptr,\n",
    "            gpu_buffers,\n",
    "            gdr,\n",
    "            memory_handles,\n",
    "            bar_ptr_data)\n",
    "        acquireThread   = threading.Thread(target=myclass.acquireData,\n",
    "                                    args=(sem,))\n",
    "        #doFFTThread     = threading.Thread(target=myclass.doFFT,\n",
    "                                    args=(sem,))\n",
    "        acquireThread.start()\n",
    "        #doFFTThread.start()\n",
    "        acquireThread.join() # Wait for acquireThread to complete\n",
    "        #doFFTThread.join()\n",
    "\n",
    "\n",
    "\n",
    "        sumFft = cp.asarray(myclass.fft).get() #convert from torch tensor to cp.array and get to cpu\n",
    "        avgPowSpec.append((sumFft/s.NOF_BUFFERS_TO_RECEIVE)**2 * 2**-34*2/(50*s.CH0_RECORD_LEN**2)*1000)\n",
    "    myclass.exit()\n",
    "\n",
    "    avgPowSpec1 = np.asarray(avgPowSpec[0::2]).mean(axis=0)\n",
    "    avgPowSpec2 = np.asarray(avgPowSpec[1::2]).mean(axis=0)\n",
    "    np.save('avgPowSpec1_3000avg_6switchPerSide_2_17_23', avgPowSpec1)\n",
    "    np.save('avgPowSpec2_3000avg_6switchPerSide_2_17_23', avgPowSpec2)\n",
    "    if 1:\n",
    "        plt.figure()\n",
    "        plt.plot(np.linspace(0,1250/s.CH0_SAMPLE_SKIP_FACTOR,s.CH0_RECORD_LEN//2),10*np.log10(avgPowSpec1[1:]))\n",
    "        plt.plot(np.linspace(0,1250/s.CH0_SAMPLE_SKIP_FACTOR,s.CH0_RECORD_LEN//2),10*np.log10(avgPowSpec2[1:]), alpha = .5)\n",
    "        plt.xlabel('Freq(MHz)')\n",
    "        plt.ylabel('Power (dBm)')\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(np.linspace(0,1250/s.CH0_SAMPLE_SKIP_FACTOR,s.CH0_RECORD_LEN//2),((avgPowSpec1-avgPowSpec2)[1:]))\n",
    "        plt.xlabel('Freq(MHz)')\n",
    "        plt.ylabel('Power (mW)')\n",
    "        plt.plot()\n",
    "        plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "565170522d23a2521d7a780d65f3ba404858b6b2c2a1aa4cc4afa9e481b8c202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
