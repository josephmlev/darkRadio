{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, find_peaks, freqz, sosfilt\n",
    "import glob\n",
    "import os\n",
    "from fnmatch import fnmatch\n",
    "import h5py\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.use('Qt5Agg')\n",
    "#plt.switch_backend('Qt5Agg')\n",
    "%matplotlib ipympl\n",
    "plt.plot(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class avgSpec:\n",
    "    def __init__(self,\n",
    "            fileList,\n",
    "            dataDir):\n",
    "\n",
    "        self.fileList = fileList\n",
    "        self.dataDir = dataDir\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def mProcAvg(self, fileList, dataDir):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes list of .h5 file names and directory, \n",
    "        returns averaged spectra (linear FFT units)\n",
    "        \n",
    "        Parameters:\n",
    "            fileList (list of strings): list of file names to be averaged \n",
    "            dataDir (str): Location of files. Realitive path.\n",
    "        \n",
    "        Returns:\n",
    "            offData (1D np arr): averaged off spectrum\n",
    "            onData (1d np arr): averaged on spectrum\n",
    "        \n",
    "        Calls:\n",
    "            avgMesData()\n",
    "        \"\"\"\n",
    "        self.totalNumAvg = 0\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = Pool(processes=24)\n",
    "            self.dataList = pool.map(self.avgMesData, fileList)\n",
    "            print('done')\n",
    "\n",
    "            #Calculate total number of FFTs in returned spectra. Each data \n",
    "            #file returns number of FFTs in dataList[data file index][2]  \n",
    "            for runningAverages in self.dataList:\n",
    "                self.totalNumAvg += runningAverages[2]\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    def avgMesData(self, aFile):\n",
    "\n",
    "        #init some parameters\n",
    "        offData = np.zeros(2**23)\n",
    "        onData = np.zeros(2**23)\n",
    "        numDataSets = 0\n",
    "        numAvgInDataFile = 0\n",
    "        \n",
    "\n",
    "\n",
    "        #itterate through file list and open h5 files in 'r(ead)' mode\n",
    "        print('ON FILE: ' + str(aFile))\n",
    "        dataBin = h5py.File(self.dataDir + aFile, 'r') #makes pointer to h5\n",
    "        numAvgInMesDataSet = int(dataBin.attrs['averages']) #total number of average for dataset\n",
    "        allKeys = [aKey for aKey in dataBin.keys()] #key is measdata. 16 per dataset\n",
    "\n",
    "        for aKey in allKeys[:]:\n",
    "            #print('ON KEY ' + str(aKey))\n",
    "            dataset = pd.read_hdf(dataDir + aFile, key = aKey) #dataframe of ROACH data (check)\n",
    "        # need to print and look at this\n",
    "            offData +=  np.asarray(dataset[dataset.keys()[0]]) #term or bicon\n",
    "            onData += np.asarray(dataset[dataset.keys()[1]]) #the other one\n",
    "            numDataSets += 1\n",
    "            numAvgInDataFile += numAvgInMesDataSet\n",
    "\n",
    "        offData /= numDataSets\n",
    "        onData /= numDataSets\n",
    "        \n",
    "        return offData, onData, numAvgInDataFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib \n",
    "plt.plot(10*np.log10(2 * 1000 * spec.dataList[0][0][1:]/ 2**48 / 50))\n",
    "plt.plot(10*np.log10(2 * 1000 * spec.dataList[0][1][1:]/ 2**48 / 50))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkFileList(dataDir):\n",
    "\n",
    "\t#get list of files in dataDir, pack data*.h5 named files into fileList\n",
    "\tdataDirContents = os.listdir(dataDir)\n",
    "\tfileList = [file for file in dataDirContents if fnmatch(file, 'data*.h5')]\n",
    "\tfileList.sort()\n",
    "\treturn fileList\n",
    "    \n",
    "dataDir = './data_7_7_22_gitignore/'\n",
    "fileList = mkFileList(dataDir)\n",
    "spec = avgSpec(fileList, dataDir)\n",
    "\n",
    "#spec.avgMesData('data_99.h5')\n",
    "#spec.avgMesData('data_98.h5')\n",
    "spec.mProcAvg(fileList[0:3], dataDir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.mProcAvg(fileList[0:60], dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.mProcAvg(fileList, dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkFileList(dataDir):\n",
    "\n",
    "\t#get list of files in dataDir, pack data*.h5 named files into fileList\n",
    "\tdataDirContents = os.listdir(dataDir)\n",
    "\tfileList = [file for file in dataDirContents if fnmatch(file, 'data*.h5')]\n",
    "\tfileList.sort()\n",
    "\treturn fileList\n",
    "\n",
    "def getData(aFile):\n",
    "\tdataDir = './data_7_7_22_gitignore/'\n",
    "\t#init some parameters\n",
    "\toffData = np.zeros(2**23)\n",
    "\tonData = np.zeros(2**23)\n",
    "\ttotalSets = 0\n",
    "\ttotalAverages = 0\n",
    "\n",
    "\n",
    "\t#itterate through file list and open h5 files in 'r(ead)' mode\n",
    "\tprint('ON FILE: ' + str(aFile))\n",
    "\tdataBin = h5py.File(dataDir + aFile, 'r') #makes pointer to h5\n",
    "\tfileAverages = int(dataBin.attrs['averages']) #total number of average for dataset\n",
    "\tallKeys = [aKey for aKey in dataBin.keys()] #key is measdata. 16 per dataset\n",
    "\n",
    "\tfor aKey in allKeys[:]:\n",
    "\t\tprint('ON KEY ' + str(aKey))\n",
    "\t\tdataset = pd.read_hdf(dataDir + aFile, key = aKey) #dataframe of ROACH data (check)\n",
    "    # need to print and look at this\n",
    "\t\toffData +=  np.asarray(dataset[dataset.keys()[0]]) #term or bicon\n",
    "\t\tonData += np.asarray(dataset[dataset.keys()[1]]) #the other one\n",
    "\t\ttotalSets += 1\n",
    "\t\ttotalAverages += fileAverages\n",
    "\n",
    "\t#signal[dBm] = mag^2 [fft units]\n",
    "\t# signal = 10log10(2[preserve power] * data[ADC units] * len(FFT)^2 * 50[Ohms] 1000[mW/W] \n",
    "\t#also! compute average. Data is sum from prev. line, divide by total sets\n",
    "\t#it is actually faster to do this all in one go because this function is IO limited\n",
    "\t#BUT! there is more averaging that needs to be done so don't go to dBm\n",
    "\t\n",
    "\t#offData = 10.*np.log10(2. * offData / totalSets  / (2**48 * 50. / 1000.))\n",
    "\t#onData = 10.*np.log10(2. * onData / totalSets  / (2**48 * 50. / 1000.))\n",
    "\n",
    "\toffData /= totalSets\n",
    "\tonData /= totalSets\n",
    "\t\n",
    "\treturn offData, onData, totalAverages\n",
    "\n",
    "\t\n",
    "def getDataBen(dataDir):\n",
    "\tfileList = sorted(\n",
    "\t\t[aFile for aFile in glob.glob(dataDir + 'data*.h5')], \n",
    "\t\tkey=lambda x: int(x[x.index('data_') + 5: x.index('.h5')])\n",
    "\t\t)\n",
    "\tprint(fileList)\n",
    "\n",
    "\n",
    "\n",
    "\toffData = np.zeros(2**23)\n",
    "\tonData = np.zeros(2**23)\n",
    "\n",
    "\ttotalSets = 0\n",
    "\ttotalAverages = 0\n",
    "\tfor aFile in fileList[:100]:\n",
    "\t\tprint('ON FILE: ' + str(aFile))\n",
    "\t\tdataBin = h5py.File(aFile, 'r')\n",
    "\t\tfileAverages = int(dataBin.attrs['averages'])\n",
    "\t\tallKeys = [aKey for aKey in dataBin.keys()]\n",
    "\n",
    "\t\tfor aKey in allKeys[:]:\n",
    "\t\t\tprint('ON KEY ' + str(aKey))\n",
    "\t\t\tdataset = pd.read_hdf(aFile, key = aKey)\n",
    "\n",
    "\t\t\toffData = offData + np.asarray(dataset[dataset.keys()[0]])\n",
    "\t\t\tonData = onData + np.asarray(dataset[dataset.keys()[1]])\n",
    "\t\t\ttotalSets += 1\n",
    "\t\t\ttotalAverages += fileAverages\n",
    "\toffData = 10.*np.log10(2. * offData / totalSets  / (2**48 * 50. / 1000.))\n",
    "\tonData = 10.*np.log10(2. * onData / totalSets  / (2**48 * 50. / 1000.))\n",
    "\n",
    "\n",
    "\treturn offData, onData, totalAverages\n",
    "\n",
    "def plotTermSigData(fileNameTerm, avgDataBicon, freqs):\n",
    "\toffDataTerm = np.zeros(2**23)\n",
    "\tonDataTerm = np.zeros(2**23)\n",
    "\n",
    "\ttotalSets = 0\n",
    "\tprint('ON FILE: ' + str(fileNameTerm))\n",
    "\tdataBin = h5py.File(fileNameTerm, 'r')\n",
    "\tallKeys = [aKey for aKey in dataBin.keys()]\n",
    "\n",
    "\tfor aKey in allKeys[:]:\n",
    "\t\tprint('ON KEY ' + str(aKey))\n",
    "\t\tdataset = pd.read_hdf(fileNameTerm, key = aKey)\n",
    "\n",
    "\t\toffDataTerm = offDataTerm + np.asarray(dataset[dataset.keys()[0]])\n",
    "\t\tonDataTerm = onDataTerm + np.asarray(dataset[dataset.keys()[1]])\n",
    "\t\ttotalSets += 1\n",
    "\n",
    "\toffDataTerm = 10.*np.log10(2. * offDataTerm / totalSets  / (2**48 * 50. / 1000.))\n",
    "\tonDataTerm = 10.*np.log10(2. * onDataTerm / totalSets  / (2**48 * 50. / 1000.))\n",
    "\tpeakIndices = find_peaks(avgDataBicon[1:] - onDataTerm[1:], threshold = 1.75)[0]\n",
    "\tpeakVals = np.asarray([(avgDataBicon[1:] - onDataTerm[1:])[x] for x in peakIndices]) \n",
    "\n",
    "\tplt.xlabel('Frequency (MHz)', labelpad = 15, **label_font)\n",
    "\tplt.ylabel('Ratio (dB)', **label_font)\n",
    "\t#plt.plot(freqs[1:], onDataTerm[1:], alpha = 0.7, label = 'Bicon Sig Gen Off')\n",
    "\tplt.plot(avgDataBicon[1:] - onDataTerm[1:], alpha = 0.7, label = 'Bicon Sig Gen On')\n",
    "\tplt.plot(peakIndices, peakVals, 'r*')\n",
    "\n",
    "\tplt.title('Ratio Bicon, Injected 123.456MHz vs No Injection')\n",
    "\tplt.show()\n",
    "\t#plt.legend(prop = legend_font)\n",
    "\treturn peakIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './data_7_7_22_gitignore/'\n",
    "fileList = mkFileList(dataDir)\n",
    "#print(fileList)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool(processes=24)\n",
    "    data = pool.map(getData, fileList[0:8])\n",
    "    #pid, offData, onData, totalAverages = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "565170522d23a2521d7a780d65f3ba404858b6b2c2a1aa4cc4afa9e481b8c202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
