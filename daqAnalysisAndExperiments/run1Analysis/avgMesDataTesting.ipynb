{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to update avgSpec class to acept a file list including mesData and update genList to accept setup text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, find_peaks, freqz, sosfilt\n",
    "import glob\n",
    "import os\n",
    "from fnmatch import fnmatch\n",
    "import h5py\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkFileList(dataDir):\n",
    "\n",
    "\t#get list of files in dataDir, pack data*.h5 named files into fileList\n",
    "\tdataDirContents = os.listdir(dataDir)\n",
    "\tfileList = [file for file in dataDirContents if fnmatch(file, 'data*.h5')]\n",
    "\tfileList.sort()\n",
    "\treturn fileList\n",
    "\n",
    "dataDir = './data_7_7_22_gitignore/'\n",
    "fileList = mkFileList(dataDir)\n",
    "\n",
    "spec102 = avgSpec(fileList[102:103], dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "import argparse\n",
    "import bisect\n",
    "import configparser\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "import h5py as h5\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys \n",
    "\"\"\"\n",
    "Convert the float parameters in the config file to floats\n",
    "Parameters:\n",
    "   aString: The string in the config file\n",
    "Returns:\n",
    "    holder (1D list): List of floats\n",
    "\"\"\"\n",
    "def getFloatBounds(aString):\n",
    "    holder = aString[aString.index('[')+1:aString.index(']')]\n",
    "    holder = holder.split(',')\n",
    "    holder = [float(x) for x in holder]\n",
    "    return holder\n",
    "\n",
    "\"\"\"\n",
    "Convert the date parameters in the config file to floats\n",
    "Parameters:\n",
    "   aString: The date string in the config file\n",
    "Returns:\n",
    "    holder (1D list): List of datetime objects written as month/day/year hour:minute:second.microseconds\n",
    "\"\"\"\n",
    "def getDateBounds(aString):\n",
    "    holder = aString[aString.index('[')+1:aString.index(']')]\n",
    "    holder = holder.split(',')\n",
    "    holder = [datetime.strptime(x.strip(), '%m/%d/%Y %H:%M:%S.%f')  for x in holder]\n",
    "    return holder\n",
    "\n",
    "\"\"\"\n",
    "Take in a config file and return a dictionary of bounds\n",
    "Parameters:\n",
    "   configFile: The config file\n",
    "   configName: The name of the configuration setup\n",
    "Returns:\n",
    "    configDict (dictionary): Dictionary of bounds\n",
    "\"\"\"\n",
    "def getAllBounds(configFile, configName):\n",
    "    configSetup = configparser.ConfigParser()\n",
    "    configSetup.read(configFile)\n",
    "    configDict = {}\n",
    "    tempBounds = getFloatBounds(configSetup[configName]['Temperature'])\n",
    "    freqBounds = getFloatBounds(configSetup[configName]['Frequency'])\n",
    "    dateBounds = getDateBounds(configSetup[configName]['Date'])\n",
    "    antWestBounds =  getFloatBounds(configSetup[configName]['AntennaWest'])\n",
    "    antVertBounds = getFloatBounds(configSetup[configName]['AntennaVert'])\n",
    "    antSouthBounds = getFloatBounds(configSetup[configName]['AntennaSouth'])\n",
    "    antThetaBounds = getFloatBounds(configSetup[configName]['AntennaTheta'])\n",
    "    antPhiBounds = getFloatBounds(configSetup[configName]['AntennaPhi'])\n",
    "    measChoice = configSetup['TEST']['Measurement']\n",
    "    configDict['Temp'] = tempBounds \n",
    "    configDict['Freq'] = freqBounds\n",
    "    configDict['Date'] = dateBounds\n",
    "    configDict['Ant'] = (antWestBounds, antVertBounds, antSouthBounds, antThetaBounds, antPhiBounds)\n",
    "    configDict['Choice'] = measChoice\n",
    "    return configDict\n",
    "\n",
    "\"\"\"\n",
    "Return the indices in the \"database\" that fall within the specified\n",
    "bound. This function assumes that the database is ordered by the \n",
    "parameter being searched for.\n",
    "Parameters:\n",
    "   val: The value in the config file\n",
    "   parsedList: List of the parameter being searched for (e.g. date/temperature/antenna position)\n",
    "Returns:\n",
    "    holderIndices: List of all the indices in the sorted list that fall in the bounds\n",
    "\"\"\"\n",
    "def parseOnce(val, parsedList):\n",
    "    if len(parsedList) == 0:\n",
    "        return []\n",
    "    \n",
    "    holderIndices = []\n",
    "    if val[0] > val[1]:\n",
    "        print('CONFUSED ORDERING')\n",
    "        return []\n",
    "    if val[0] == -1:\n",
    "        startIndex = 0\n",
    "    elif val[0] < parsedList[0]:\n",
    "        startIndex = 0\n",
    "    elif val[0] > parsedList[-1]:\n",
    "        print('EMPTY LIST')\n",
    "        return []\n",
    "    else:\n",
    "        startIndex = bisect.bisect_left(parsedList, val[0])\n",
    "    if val[1] == -1:\n",
    "        endIndex = len(parsedList)\n",
    "    elif val[1] > parsedList[-1]:\n",
    "        endIndex = len(parsedList)\n",
    "    else:\n",
    "        endIndex = bisect.bisect_right(parsedList, val[1])\n",
    "    \n",
    "    [holderIndices.append(x) for x in range(startIndex, endIndex)]    \n",
    "    return holderIndices\n",
    "\n",
    "\"\"\"\n",
    "Obtain all the datasets that fall within the bounds given in the config\n",
    "file.\n",
    "Parameters:\n",
    "   configFile: The name of the configuration file\n",
    "   configName: The name of the configuration setup in the config file \n",
    "Returns:\n",
    "    parsedList: List of all the parsed data files defined as a list of tuples\n",
    "                of the form ((file number, save number), date, temperature, antenna position).)\n",
    "                    - Date is a datetime object\n",
    "                    - Antenna position is a tuple of the form (west, vertical, south, theta, phi)\n",
    "\n",
    "\"\"\"\n",
    "def getParsedList(configFile, configName, dbFile):\n",
    "    allData = []\n",
    "    configDict = getAllBounds(configFile, configName)\n",
    "    with open(dbFile, 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            holder = line.split()\n",
    "            holder = [x.replace(',', '') if counter > 0 else x for counter, x in enumerate(holder)]\n",
    "            try:\n",
    "                dateVal = datetime.strptime(holder[1] + ' ' + holder[2], '%Y-%m-%d %H:%M:%S.%f')\n",
    "            except:\n",
    "                 dateVal = datetime.strptime(holder[1] + ' ' + holder[2], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            tempVal = float(holder[3])\n",
    "            antPos = (float(holder[4][1:]), float(holder[5]), float(holder[6]), float(holder[7]), float(holder[8][:-1]))\n",
    "            fileNum = float(holder[0][1:holder[0].index(',')])\n",
    "            runNum = float(holder[0][holder[0].index(',')+1:-2])\n",
    "            allData.append(((fileNum, runNum), dateVal, tempVal, antPos))\n",
    "    \n",
    "    holderIndices = []\n",
    "    allData = sorted(allData, key = lambda x: x[1])\n",
    "    parsedList = allData\n",
    "    for val in np.reshape(configDict['Date'], (-1, 2)):\n",
    "        [holderIndices.append(x) for x in parseOnce(val, [x[1] for x in parsedList])]\n",
    "    \n",
    "    holderIndices = np.asarray([*set(holderIndices)])\n",
    "    parsedList = [parsedList[x] for x in holderIndices]\n",
    "    \n",
    "\n",
    "# configDict['Ant'] = (antWestBounds, antVertBounds, antSouthBounds, antThetaBounds, antPhiBounds)\n",
    "# allData.append(((fileNum, runNum), dateVal, tempVal, antPos, antPos))\n",
    "\n",
    "    for antSortVal in range(len(configDict['Ant'])):\n",
    "        parsedList = sorted(parsedList, key = lambda x: x[3][antSortVal])\n",
    "        holderIndices = []\n",
    "        for val in np.reshape(configDict['Ant'][antSortVal], (-1, 2)):\n",
    "            [holderIndices.append(x) for x in parseOnce(val, [x[3][0] for x in parsedList])]\n",
    "\n",
    "        holderIndices = np.asarray([*set(holderIndices)])\n",
    "        parsedList = [parsedList[x] for x in holderIndices]\n",
    "\n",
    "    parsedList = sorted(parsedList, key = lambda x: x[2])\n",
    "    holderIndices = []\n",
    "    for val in np.reshape(configDict['Temp'], (-1, 2)):\n",
    "        [holderIndices.append(x) for x in parseOnce(val, [x[2] for x in parsedList])]\n",
    "    \n",
    "    holderIndices = np.asarray([*set(holderIndices)])\n",
    "    parsedList = [parsedList[x] for x in holderIndices]  \n",
    "    \n",
    "    parsedList = sorted(parsedList, key=lambda x: (x[0][0], x[0][1]))\n",
    "    return parsedList, configDict\n",
    "    #[print(x) for x in parsedList]\n",
    "\n",
    "\n",
    "\n",
    "#num_arrays = 100\n",
    "num_processes = mp.cpu_count()\n",
    "num_simulations = 1000\n",
    "sentinel = None\n",
    "\n",
    "\"\"\"\n",
    "Read the associated files in the parsed file list and store the data in\n",
    "a queue, which is written to a file. All this is done using multiprocessing\n",
    "speed up the read times. \n",
    "Parameters:\n",
    "   readQueue: The queue that contains all the files to be written to a file. Stored in the following\n",
    "              structure: (file number, list of data tuples)\n",
    "                - tuple is of the form (measurement number, tuple of parameters)\n",
    "                    o Tuple of parameters is of the form \n",
    "                      (save number, date, temperature, antenna position, frequency, measurement choice)\n",
    "                        x Date is a datetime object\n",
    "                        x Antenna position is a tuple of the form (west, vertical, south, theta, phi)\n",
    "                        x Measurement choice is a string that is either 'Antenna', 'Terminator', or 'Both'\n",
    "\n",
    "   output: The name of the output queue. Stored in the following structure: (data, tuple of parameters)\n",
    "                - data is an numpy array of either antenna or terminator data or two arrays\n",
    "                  if the measurement choice is both\n",
    "                - Tuple paramters is of the form (measurement number, tuple of parameters) exactly\n",
    "                  like the read queue\n",
    "    \n",
    "    dataDir: The directory where the data files are stored\n",
    "Returns:\n",
    "    Nothing. Puts data in a queue\n",
    "\n",
    "\"\"\"\n",
    "def collectData(readQueue, output, dataDir):\n",
    "    freqStep = 6.0*10**8/2**23\n",
    "    antData = []\n",
    "    termData = []\n",
    "    for parsedVal in iter(readQueue.get, sentinel):\n",
    "        aFile = 'data_' + str(parsedVal[0]) + '.h5'\n",
    "        #print(parsedVal)\n",
    "        for writeData in parsedVal[1]:\n",
    "            #print('TEST: ' + str(writeData[0]))\n",
    "            dataset = pd.read_hdf(dataDir + aFile, key = 'measdata_'+ str(writeData[0])) \n",
    "            startFreq = writeData[1][3][0]\n",
    "            endFreq = writeData[1][3][1]\n",
    "            startIndex = int(startFreq*10**6 / freqStep)\n",
    "            endIndex = int(endFreq*10**6/freqStep)\n",
    "            if writeData[1][4] == 'Antenna' or writeData[1][4] == 'Both':\n",
    "                antData = np.asarray(dataset[dataset.keys()[1]])[startIndex:endIndex] #the other one\n",
    "            if writeData[1][4] == 'Terminator' or writeData[1][4] == 'Both':\n",
    "                termData =  np.asarray(dataset[dataset.keys()[0]])[startIndex:endIndex] #term or bicon \n",
    "            if len(antData) == 0:\n",
    "                output.put((termData, writeData))\n",
    "            elif len(termData) == 0:\n",
    "                output.put((antData, writeData))\n",
    "            else:\n",
    "                output.put((antData, termData, writeData))\n",
    "    \n",
    "            antData = []\n",
    "            termData = []\n",
    "       \n",
    "\"\"\"\n",
    "Write the data stored in the output queue to an .h5 file. Right now, only a single .h5 file\n",
    "is saved, which can get large very quickly if too small of a subset of data are taken\n",
    "Parameters:\n",
    "   output: The name of the output queue. Stored in the following structure: (data, tuple of parameters)\n",
    "                - data is an numpy array of either antenna or terminator data or two arrays\n",
    "                  if the measurement choice is both\n",
    "                - Tuple paramters is of the form (measurement number, tuple of parameters) exactly\n",
    "                  like the read queue\n",
    "    Returns:\n",
    "    Nothing. Saves data to an .h5 in the same directory as where the script is called (change this)\n",
    "\n",
    "\"\"\"\n",
    "def writeFiles(output):\n",
    "    #hdf = pt.openFile('simulation.h5', mode='w')\n",
    "    aFile = h5.File('/group/tysongrp/RQTest.h5', 'w')\n",
    "    first = True\n",
    "    biconCounter = 0\n",
    "    termCounter = 0\n",
    "    while True:\n",
    "        data = output.get()\n",
    "        if first:\n",
    "            freqStep = 6.0*10**8/2**23\n",
    "            freqs = np.asarray(range(len(data[0])))*freqStep\n",
    "            aFile.create_dataset('Freqs', data = freqs)\n",
    "            first = False    \n",
    "        if data:\n",
    "            if data[-1][1][4] == 'Both':\n",
    "                dataBicon = aFile.create_dataset('bicon_' + str(biconCounter), data=data[0])\n",
    "                dataBicon.attrs['Date'] = str(data[-1][1][0])\n",
    "                dataBicon.attrs['Run'] = str(data[-1][0])\n",
    "                dataBicon.attrs['Antenna West'] = str(data[-1][1][2][0])\n",
    "                dataBicon.attrs['Antenna Vertical'] = str(data[-1][1][2][1])\n",
    "                dataBicon.attrs['Antenna South'] = str(data[-1][1][2][2])\n",
    "                dataBicon.attrs['Antenna Theta'] = str(data[-1][1][2][3])\n",
    "                dataBicon.attrs['Antenna Phi'] = str(data[-1][1][2][4])\n",
    "                dataBicon.attrs['Temperature'] = str(data[-1][1][1])\n",
    "\n",
    "                dataTerm = aFile.create_dataset('term_' + str(termCounter), data =data[1])\n",
    "                \n",
    "                dataTerm.attrs['Date'] = str(data[-1][1][0])\n",
    "                biconCounter += 1\n",
    "                termCounter += 1\n",
    "        else:\n",
    "            break\n",
    "    #hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    writeH5 = False\n",
    "    # Name of the configuration file\n",
    "    configFile = '/group/tysongrp/ConfigDR.ini'\n",
    "    # Name of the setup in the configuration file\n",
    "    configName = 'TEST'\n",
    "    # Get a parsed list of file names and also saves bounds to a dictionary\n",
    "    parsedList, configDict = getParsedList(configFile, configName)\n",
    "    RQTextFile = './RQFiles.txt'\n",
    "    with(open(RQTextFile, 'w') as f):\n",
    "        f.write('FILE NUMBER  RUN NUMBER  FREQUENCY RANGE (MHZ)  DATE  TEMPERATURE  ANTENNA POSITION (W/V/S,THETA,PHI)\\n')\n",
    "        for aVal in parsedList:\n",
    "            aDate = aVal[1].strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "            f.write((str(aVal[0][0])+ '  ' + str(aVal[0][1]) + '  ' + str(aDate) + '  ' + str(configDict['Freq'][0]) + '-' + str(configDict['Freq'][1]) + '  ' + str(aVal[2]) + '  ' + str(aVal[3])) + '\\n')\n",
    "            #print(configDict['Freq'])\n",
    "    \n",
    "    if writeH5:\n",
    "        parsedDict = {}\n",
    "        # Create a dictionary of lists of tuples (see the description for collectData). Doing this\n",
    "        # makes it possible to parallelize the read operation\n",
    "        for val in parsedList:\n",
    "            keyVal = str(int(val[0][0]))\n",
    "            if keyVal not in parsedDict:\n",
    "                parsedDict[keyVal] = []\n",
    "            \n",
    "            # This will make it a little annoying to add more parameters to cut on\n",
    "            parsedDict[keyVal].append((int(val[0][1]), (val[1], val[2], val[3], configDict['Freq'], configDict['Choice']))) \n",
    "\n",
    "    \n",
    "        # List of keys (file numbers) in the parameter dictionary\n",
    "        parsedKeys = [aKey for aKey in parsedDict]\n",
    "        dataDir = '/group/tysongrp/JulyRun_7-7-22/Data/'\n",
    "        #for aKey in parsedDict:\n",
    "        #    aFile = 'data_' + str(aKey) + '.h5'\n",
    "        #    dataBin = h5.File(dataDir + aFile, 'r')\n",
    "        #    for anAverage in parsedDict[aKey]:\n",
    "        #        print(dataBin['measdata_' + str(anAverage[0])])\n",
    "\n",
    "        # Create the read/write queues\n",
    "        writeQueue = mp.Queue()\n",
    "        readQueue = mp.Queue()\n",
    "        # Add data to the read queue\n",
    "        [readQueue.put((aKey, parsedDict[aKey])) for aKey in parsedKeys] \n",
    "        \n",
    "        # Start the write process\n",
    "        proc = mp.Process(target=writeFiles, args=(writeQueue, ))\n",
    "        jobs = []\n",
    "        proc.start()\n",
    "\n",
    "        # Create the read processes\n",
    "        for i in range(num_processes):\n",
    "            p = mp.Process(target=collectData, args=(readQueue, writeQueue, dataDir))\n",
    "            jobs.append(p)\n",
    "            p.start()\n",
    "        for i in range(num_processes):\n",
    "            # Send the sentinal to tell Simulation to end\n",
    "            readQueue.put(sentinel)\n",
    "        for p in jobs:\n",
    "            p.join()\n",
    "        writeQueue.put(None)\n",
    "        proc.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3451319139.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [43]\u001b[0;36m\u001b[0m\n\u001b[0;31m    configFile = './ConfigDR.ini'\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#mkFileList updated\n",
    "\n",
    "\n",
    "def mkFileList(dataDir, configFile, dbFile, configName):\n",
    "    #get list of tuples, (file, mesData) indicated in configFile \n",
    "    # in dataDir, pack data*.h5 named files into fileList\n",
    "\n",
    "    '''\n",
    "    Get a parsed list of file names and also saves bounds to a dictionary\n",
    "    getParsed List\n",
    "    Returns:\n",
    "    parsedList: List of all the parsed data files defined as a list of tuples of the form \n",
    "        ((file number, save number), date, temperature, antenna position).)\n",
    "        - Date is a datetime object\n",
    "        - Antenna position is a tuple of the form (west, vertical, south, theta, phi)\n",
    "    configDict: dict of info in the config file used to generate parsedList\n",
    "        keys:\n",
    "        -Temp (temperture)\n",
    "        -Freq (frequancy range)\n",
    "        -Date (datetime object)\n",
    "        -Ant (position. tuple of the form (west, vertical, south, theta, phi))\n",
    "    '''\n",
    "    parsedList, configDict = getParsedList(configFile, configName, dbFile)\n",
    "\n",
    "    dataDirContents = os.listdir(dataDir)\n",
    "    dataDirContentsList = [file for file in dataDirContents if fnmatch(file, 'data*.h5')]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# Name of the configuration and database files\n",
    "configFile = './ConfigDR.ini'\n",
    "dbFile = './SearchableDatabase.txt'\n",
    "# Name of the setup in the configuration file\n",
    "configName = 'TEST'\n",
    "dataDir = ('../../../../../drBiggerBoy/drData/Data')\n",
    "mkFileList(dataDir, configFile, dbFile, configName)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('length parsed list = ',len(parsedList))\n",
    "print('length parsed list/735 data file = ', len(parsedList)/735)\n",
    "print()\n",
    "for element in parsedList:\n",
    "    print(element)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class avgSpec:\n",
    "    '''\n",
    "    Inputs:\n",
    "        fileList(list):\n",
    "        List of file names of form `data_<n>.h5`\n",
    "\n",
    "        dataDir(string): \n",
    "        Realitive path to data directory\n",
    "\n",
    "        numProc(int):\n",
    "        Number of processes to open data files.\n",
    "\n",
    "    Methods:\n",
    "        avgMesDataAll: worker. averages together all measData in a single data file\n",
    "        compAvgAll: calls avgMesData in parallel\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "        parsedList,\n",
    "        dataDir,\n",
    "        numProc = 28,\n",
    "        verbose = False):\n",
    "\n",
    "        self.parsedList = parsedList\n",
    "        self.dataDir = dataDir\n",
    "        self.numProc = numProc\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.antData = np.zeros(2**23)\n",
    "        self.termData = np.zeros(2**23)\n",
    "        \n",
    "        #can pull these out of data files later\n",
    "        self.startFreq = 0\n",
    "        self.stopFreq = 300\n",
    "        numBins = 8388607\n",
    "        self.freqs = np.linspace(self.startFreq, self.stopFreq, numBins)\n",
    "\n",
    "        self.setSpecDictsAndFileList(parsedList)\n",
    "        print('hello')\n",
    "        self.computeAvgAll()\n",
    "\n",
    "    \n",
    "    \n",
    "    def avgMesDataAll(self, aFile):\n",
    "        '''\n",
    "        Worker function to open a data file and average ALL mesData. Called by computeAvgAll\n",
    "\n",
    "        Parameters:\n",
    "            self.dataDir (str): Location of files. Realitive path.\n",
    "            aSpec (tuple): specifies a spectrum. (fileName(str), mesData(int)) \n",
    "\n",
    "        Returns:\n",
    "            antData (1D np arr): averaged off spectrum (linear FFT units)\n",
    "            termData (1D np arr): averaged on spectrum (linear FFT units)\n",
    "            numAvgInDataFile (int): number of averages in data file.\n",
    "        '''\n",
    "        #init some parameters\n",
    "        antData = np.zeros(2**23)\n",
    "        termData = np.zeros(2**23)\n",
    "        numDataSets = 0\n",
    "        numAvgInDataFile = 0\n",
    "\n",
    "        #itterate through file list and open h5 files in 'r(ead)' mode\n",
    "        if self.verbose == True:\n",
    "            print('ON FILE: ' + str(aFile))\n",
    "        dataBin = h5py.File(self.dataDir + aFile, 'r') #makes pointer to h5\n",
    "        numAvgInMesDataSet = int(dataBin.attrs['averages']) #total number of average for dataset\n",
    "        allKeys = [aKey for aKey in dataBin.keys()] #key is measdata. 16 per dataset\n",
    "\n",
    "        for aKey in allKeys[:]:\n",
    "            dataset = pd.read_hdf(self.dataDir + aFile, key = aKey) #dataframe of ROACH data (check)\n",
    "        # need to print and look at this\n",
    "            termData +=  np.asarray(dataset[dataset.keys()[0]]) #term or bicon\n",
    "            antData += np.asarray(dataset[dataset.keys()[1]]) #the other one\n",
    "            numDataSets += 1\n",
    "            numAvgInDataFile += numAvgInMesDataSet\n",
    "\n",
    "        antData /= numDataSets\n",
    "        termData /= numDataSets\n",
    "        \n",
    "        return antData, termData, numAvgInDataFile\n",
    "\n",
    "    def avgMesData(self, aFile):\n",
    "        '''\n",
    "        Worker function to open a data file and average SELECT mesData. Called by computeAvgAll\n",
    "\n",
    "        Parameters:\n",
    "            self.dataDir (str): Location of files. Realitive path.\n",
    "            aFile (tuple): specifies a spectrum. (fileName(str), mesData(int)) \n",
    "\n",
    "        Returns:\n",
    "            antData (1D np arr): averaged off spectrum (linear FFT units)\n",
    "            termData (1D np arr): averaged on spectrum (linear FFT units)\n",
    "            numAvgInDataFile (int): number of averages in data file.\n",
    "        '''\n",
    "        #init some parameters\n",
    "        antData = np.zeros(2**23)\n",
    "        termData = np.zeros(2**23)\n",
    "        numDataSets = 0\n",
    "        numAvgInDataFile = 0\n",
    "\n",
    "        #itterate through file list and open h5 files in 'r(ead)' mode\n",
    "        if self.verbose == True:\n",
    "            print('ON FILE: ' + str(aSpec[0]))\n",
    "        dataBin = h5py.File(self.dataDir + aSpec[0], 'r') #makes pointer to h5\n",
    "        numAvgInMesDataSet = int(dataBin.attrs['averages']) #total number of average for dataset\n",
    "\n",
    "        ##########old code\n",
    "        allKeys = [aKey for aKey in dataBin.keys()] #key is measdata. 16 per dataset\n",
    "     \n",
    "        ####new\n",
    "\n",
    "        ###\n",
    "\n",
    "\n",
    "\n",
    "        for aKey in allKeys[:]:\n",
    "            dataset = pd.read_hdf(self.dataDir + aFile, key = aKey) #dataframe of ROACH data (check)\n",
    "        # need to print and look at this\n",
    "            termData +=  np.asarray(dataset[dataset.keys()[0]]) #term or bicon\n",
    "            antData += np.asarray(dataset[dataset.keys()[1]]) #the other one\n",
    "            numDataSets += 1\n",
    "            numAvgInDataFile += numAvgInMesDataSet\n",
    "\n",
    "        antData /= numDataSets\n",
    "        termData /= numDataSets\n",
    "        \n",
    "        return antData, termData, numAvgInDataFile\n",
    "\n",
    "    def avgDataList(self):\n",
    "        '''\n",
    "        Parameters:\n",
    "            self.dataList (list of len=self.fileList): Each element of dataList contains a len=3 tuple\n",
    "                which contains (antData (arr of len=numBins), \n",
    "                                termData (arr of len=numBins), \n",
    "                                numAvgInDataFile (int))\n",
    "        \n",
    "        Sets:\n",
    "            self.antData (1D np arr): averaged off spectrum (linear FFT units)\n",
    "            self.termData (1D np arr): averaged on spectrum (linear FFT units)\n",
    "        '''\n",
    "     \n",
    "        antData = np.zeros(2**23)\n",
    "        termData = np.zeros(2**23)\n",
    "        numDataFiles = 0\n",
    "\n",
    "        for dataTuple in self.dataList:\n",
    "            antData += dataTuple[0]\n",
    "            termData += dataTuple[1]\n",
    "            numDataFiles += 1\n",
    "        \n",
    "        self.antData = antData / numDataFiles\n",
    "        self.termData = termData / numDataFiles\n",
    "        \n",
    "    def setSpecDictsAndFileList(self, parsedList):\n",
    "        '''\n",
    "        setter method for: \n",
    "        fileList: list of str(fileName))\n",
    "        specNumDict: dict. Keys int(fileNum), contains list(int(specNum))\n",
    "        specNameDict: dict. Keys str(fileName), contains list(str(specName))\n",
    "\n",
    "        input:\n",
    "        parsedList - list of tuples (float(fileNum), float(specNum))\n",
    "        '''\n",
    "        #init stuff\n",
    "        fileList = []\n",
    "        specNameDict = {}\n",
    "        specNumDict = {}\n",
    "        for scan in parsedList:\n",
    "            #get names and numbers for each specta's number and file number\n",
    "            #convert from float to either int or string\n",
    "            fileNum = int(scan[0][0])\n",
    "            fileName = 'data_' + str(fileNum) + '.h5'\n",
    "            scanNum = int(scan[0][1])\n",
    "            scanName = 'mesdata_' + str(scanNum)\n",
    "            #append them to approprate lists/stuff dicts\n",
    "            fileList.append(fileName)\n",
    "            specNameDict.update({fileName : scanName})\n",
    "            specNumDict.update({fileNum : scanNum})\n",
    "            #specNameList.append((fileName,scanName))\n",
    "            #specNumList.append((fileNum,scanNum))\n",
    "        #set things\n",
    "        self.fileList = fileList\n",
    "        self.specNameDict = specNameDict\n",
    "        self.specNumDict = specNumDict\n",
    "\n",
    "        print(self.specNumDict)\n",
    "\n",
    "\n",
    "    def setFileList(self):\n",
    "        '''\n",
    "        Replaced by setFileAndSpecLists\n",
    "        '''\n",
    "        fileList = []\n",
    "        for scan in self.parsedList:\n",
    "            fileNum = int(scan[0][0])\n",
    "            fileName = 'data_' + str(fileNum) + '.h5'\n",
    "            scanNum = int(scan[0][1])\n",
    "            scanName = 'mesdata_' + str(scanNum)\n",
    "            fileList.append((fileName,scanName))\n",
    "        self.fileList = fileList\n",
    "\n",
    "\n",
    "\n",
    "    def computeAvg(self):\n",
    "        '''\n",
    "        Opens each file in fileList and computes an average of SELECTED measData in each data file.\n",
    "        Then averages each of these averages together. \n",
    "\n",
    "        Parameters:\n",
    "            self.fileList - list of strings of file names to be averaged\n",
    "            self.specNameList - list of tuples of (str(fileName), str(specNam))\n",
    "            self.specNumList - list of tuples of (int(fileNum), int(specNum))\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Sets:\n",
    "            self.dataList (list of len=self.fileList): Each element of dataList contains a len=3 tuple\n",
    "                which contains (antData (arr of len=numBins), \n",
    "                                termData (arr of len=numBins), \n",
    "                                numAvgInDataFile (int))\n",
    "             \n",
    "        Calls:\n",
    "            avgMesDataAll(): worker function. Averages together ALL mesData in a data file\n",
    "        '''\n",
    "        tStart = time.time()\n",
    "\n",
    "        self.setFileList()\n",
    "\n",
    "        print('Starting to open', len(self.fileList),\n",
    "                'files and avgerage mesData with', self.numProc, 'processes')\n",
    "        if 1: #__name__ == '__main__': #does not import with name == main. Removing it fixes issue. Come back to this\n",
    "            #Multiprocessing. Each process (pool) computes an \n",
    "            #average spectra on ALL of a single data file's measData.\n",
    "            pool = Pool(processes = self.numProc)\n",
    "            self.dataList = pool.map(self.avgMesData, self.fileList)\n",
    "\n",
    "            #Calculate total number of FFTs in returned spectra. Each data \n",
    "            #file returns number of FFTs in dataList[data file index][2]  \n",
    "            self.totalNumAvg = 0\n",
    "            for runningAverages in self.dataList:\n",
    "                self.totalNumAvg += runningAverages[2]\n",
    "        tMesData = time.time()\n",
    "\n",
    "        #print('Done opening. Now averaging dataFile arrays together') \n",
    "        self.avgDataList()\n",
    "        tDone = time.time()\n",
    "\n",
    "        print('time to open and avg mes data =', tMesData - tStart)\n",
    "        print('Done. Total time =', tDone - tStart)\n",
    "\n",
    "\n",
    "\n",
    "    def computeAvgAll(self):\n",
    "        '''\n",
    "        Opens each file in fileList and computes an average of ALL measData in each data file.\n",
    "        Then averages each of these averages together. \n",
    "\n",
    "        Parameters:\n",
    "            self.fileList (list of strings): list of file names to be averaged\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Sets:\n",
    "            self.dataList (list of len=self.fileList): Each element of dataList contains a len=3 tuple\n",
    "                which contains (antData (arr of len=numBins), \n",
    "                                termData (arr of len=numBins), \n",
    "                                numAvgInDataFile (int))\n",
    "             \n",
    "        Calls:\n",
    "            avgMesDataAll(): worker function. Averages together ALL mesData in a data file\n",
    "        '''\n",
    "        tStart = time.time()\n",
    "\n",
    "        self.setFileList()\n",
    "\n",
    "        print('Starting to open', len(self.fileList),\n",
    "                'files and avgerage mesData with', self.numProc, 'processes')\n",
    "        if 1: #__name__ == '__main__': #does not import with name == main. Removing it fixes issue. Come back to this\n",
    "            #Multiprocessing. Each process (pool) computes an \n",
    "            #average spectra on ALL of a single data file's measData.\n",
    "            pool = Pool(processes = self.numProc)\n",
    "            self.dataList = pool.map(self.avgMesData, self.fileList)\n",
    "\n",
    "            #Calculate total number of FFTs in returned spectra. Each data \n",
    "            #file returns number of FFTs in dataList[data file index][2]  \n",
    "            self.totalNumAvg = 0\n",
    "            for runningAverages in self.dataList:\n",
    "                self.totalNumAvg += runningAverages[2]\n",
    "        tMesData = time.time()\n",
    "\n",
    "        #print('Done opening. Now averaging dataFile arrays together') \n",
    "        self.avgDataList()\n",
    "        tDone = time.time()\n",
    "\n",
    "        print('time to open and avg mes data =', tMesData - tStart)\n",
    "        print('Done. Total time =', tDone - tStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487.0, 7805.0)\n",
      "(487.0, 7806.0)\n",
      "(487.0, 7807.0)\n",
      "(488.0, 7808.0)\n",
      "(575.0, 9208.0)\n",
      "(575.0, 9209.0)\n",
      "(575.0, 9210.0)\n",
      "(575.0, 9211.0)\n",
      "{487: 7807, 488: 7808, 575: 9211}\n",
      "hello\n",
      "Starting to open 8 files and avgerage mesData with 28 processes\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aSpec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_2837868/889522154.py\", line 105, in avgMesData\n    dataBin = h5py.File(self.dataDir + aSpec[0], 'r') #makes pointer to h5\nNameError: name 'aSpec' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m spec \u001b[39min\u001b[39;00m parsedList:\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(spec[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m specData \u001b[39m=\u001b[39m avgSpec(parsedList, dataDir)\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mavgSpec.__init__\u001b[0;34m(self, parsedList, dataDir, numProc, verbose)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetSpecDictsAndFileList(parsedList)\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhello\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomputeAvgAll()\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mavgSpec.computeAvgAll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m: \u001b[39m#__name__ == '__main__': #does not import with name == main. Removing it fixes issue. Come back to this\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[39m#Multiprocessing. Each process (pool) computes an \u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39m#average spectra on ALL of a single data file's measData.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     pool \u001b[39m=\u001b[39m Pool(processes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumProc)\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataList \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mavgMesData, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfileList)\n\u001b[1;32m    287\u001b[0m     \u001b[39m#Calculate total number of FFTs in returned spectra. Each data \u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[39m#file returns number of FFTs in dataList[data file index][2]  \u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotalNumAvg \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=358'>359</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=359'>360</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=360'>361</a>\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=361'>362</a>\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=362'>363</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=363'>364</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=768'>769</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[1;32m    <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=769'>770</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/dradmin/miniconda3/lib/python3.9/multiprocessing/pool.py?line=770'>771</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aSpec' is not defined"
     ]
    }
   ],
   "source": [
    "# Name of the configuration and database files\n",
    "configFile = './ConfigDR.ini'\n",
    "dbFile = './SearchableDatabase.txt'\n",
    "# Name of the setup in the configuration file\n",
    "configName = 'TEST'\n",
    "dataDir = ('../../../../../drBiggerBoy/drData/Data/')\n",
    "\n",
    "parsedList, configDict = getParsedList(configFile, configName, dbFile)\n",
    "for spec in parsedList:\n",
    "    print(spec[0])\n",
    "\n",
    "specData = avgSpec(parsedList, dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: [1, 3], 5: 'test'}\n"
     ]
    }
   ],
   "source": [
    "fullList = [1,2,3,4,5]\n",
    "subSet = [1,3]\n",
    "\n",
    "testDict = {6 : subSet}\n",
    "\n",
    "testDict.update({5 : 'test'})\n",
    "print(testDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "565170522d23a2521d7a780d65f3ba404858b6b2c2a1aa4cc4afa9e481b8c202"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
